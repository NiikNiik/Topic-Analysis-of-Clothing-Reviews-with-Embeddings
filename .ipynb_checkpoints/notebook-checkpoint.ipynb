{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63eb2488-c1e9-4093-b390-cd3e16778188",
   "metadata": {},
   "source": [
    "## Analyzing Customer Sentiment in E-Commerce Reviews\n",
    "\n",
    "Customer feedback is a goldmine of insights, and I wanted to explore just how much you can learn from it. For this personal project, I worked with the Women's Clothing E-Commerce Reviews dataset, focusing on the 'Review Text' column — a rich collection of direct customer opinions about their shopping experience and product quality.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "Using Python and text embedding techniques, I analyzed the review data to uncover underlying themes and sentiment patterns. The goal was to gain a deeper understanding of customer satisfaction and identify potential areas for improving products and services.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset I used was:\n",
    "\n",
    "## womens_clothing_e-commerce_reviews.csv\n",
    "\n",
    "| Column        | Description                           |\n",
    "|---------------|---------------------------------------|\n",
    "| `'Review Text'` | Textual feedback provided by customers about their shopping experience and product quality. |\n",
    "\n",
    "I leveraged modern embedding APIs to convert raw text into high-dimensional vectors. From there, I performed clustering and sentiment analysis to group similar reviews and highlight common pain points and praises. This allowed me to summarize the voice of the customer in a way that’s scalable and actionable.\n",
    "\n",
    "This project helped sharpen my skills in NLP, data preprocessing, and insight communication — and it was a great reminder of the power hidden in unstructured data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be4be70-4ed9-451d-a78d-2217e1f93fd5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1721657868674,
    "lastExecutedByKernel": "1aec7d63-06a0-4477-8a55-4382968032ed",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Initialize your API key\nimport os\n\nopen_api_key = os.environ[\"OPEN_API_KEY\"]"
   },
   "outputs": [],
   "source": [
    "# Initialize your API key\n",
    "import os\n",
    "\n",
    "open_api_key = os.environ[\"OPEN_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab9156-8915-458d-88d7-013e3e2f2adb",
   "metadata": {},
   "source": [
    "## Install useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502da6dc-fe7d-427e-8f2b-ad0f1c0065ce",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 3780,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1721657887258,
    "lastExecutedByKernel": "1aec7d63-06a0-4477-8a55-4382968032ed",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Update OpenAI to 1.3\nfrom importlib.metadata import version\ntry:\n    assert version('openai') == '1.3.0'\nexcept:\n    !pip install openai==1.3.0\nimport openai",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai==1.3.0\n",
      "  Downloading openai-1.3.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (3.6.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (1.10.12)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.8/dist-packages (from openai==1.3.0) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<4,>=3.5.0->openai==1.3.0) (2.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.5.0->openai==1.3.0) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai==1.3.0) (2019.11.28)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.8/dist-packages (from httpx<1,>=0.23.0->openai==1.3.0) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.8/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.0) (0.14.0)\n",
      "Downloading openai-1.3.0-py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "\u001b[33m  WARNING: The script openai is installed in '/home/repl/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openai-1.3.0\n"
     ]
    }
   ],
   "source": [
    "# Update OpenAI to 1.3\n",
    "from importlib.metadata import version\n",
    "try:\n",
    "    assert version('openai') == '1.3.0'\n",
    "except:\n",
    "    !pip install openai==1.3.0\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddadff7d-c146-46fc-a2b1-b32a3082b08a",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 5314,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1704814765988,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run this cell to install ChromaDB if desired\ntry:\n    assert version('chromadb') == '0.4.17'\nexcept:\n    !pip install chromadb==0.4.17\ntry:\n    assert version('pysqlite3') == '0.5.2'\nexcept:\n    !pip install pysqlite3-binary==0.5.2\n__import__('pysqlite3')\nimport sys\nsys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\nimport chromadb",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pysqlite3-binary==0.5.2 in /home/repl/.local/lib/python3.8/site-packages (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to install ChromaDB if desired\n",
    "try:\n",
    "    assert version('chromadb') == '0.4.17'\n",
    "except:\n",
    "    !pip install chromadb==0.4.17\n",
    "try:\n",
    "    assert version('pysqlite3') == '0.5.2'\n",
    "except:\n",
    "    !pip install pysqlite3-binary==0.5.2\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f7ea8-4e12-4b2a-9703-ea3c54ee19af",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "Load data and perform basic data checks to ensure you are using relevant data for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e0c038-27df-4468-b766-abaf20f53622",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53,
    "lastExecutedAt": 1704814766043,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load the dataset\nimport pandas as pd\nreviews = pd.read_csv(\"womens_clothing_e-commerce_reviews.csv\")\n\n# Display the first few entries\nreviews.head()",
    "outputsMetadata": {
     "0": {
      "height": 201,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "Age": [
          33,
          34,
          60,
          50,
          47
         ],
         "Class Name": [
          "Intimates",
          "Dresses",
          "Dresses",
          "Pants",
          "Blouses"
         ],
         "Clothing ID": [
          767,
          1080,
          1077,
          1049,
          847
         ],
         "Department Name": [
          "Intimate",
          "Dresses",
          "Dresses",
          "Bottoms",
          "Tops"
         ],
         "Division Name": [
          "Initmates",
          "General",
          "General",
          "General Petite",
          "General"
         ],
         "Positive Feedback Count": [
          0,
          4,
          0,
          0,
          6
         ],
         "Rating": [
          4,
          5,
          3,
          5,
          5
         ],
         "Recommended IND": [
          1,
          1,
          0,
          1,
          1
         ],
         "Review ID": [
          0,
          1,
          2,
          3,
          4
         ],
         "Review Text": [
          "Absolutely wonderful - silky and sexy and comfortable",
          "Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.",
          "I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c",
          "I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!",
          "This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!"
         ],
         "Title": [
          null,
          null,
          "Some major design flaws",
          "My favorite buy!",
          "Flattering shirt"
         ],
         "index": [
          0,
          1,
          2,
          3,
          4
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "Review ID",
           "type": "integer"
          },
          {
           "name": "Clothing ID",
           "type": "integer"
          },
          {
           "name": "Age",
           "type": "integer"
          },
          {
           "name": "Title",
           "type": "string"
          },
          {
           "name": "Review Text",
           "type": "string"
          },
          {
           "name": "Rating",
           "type": "integer"
          },
          {
           "name": "Recommended IND",
           "type": "integer"
          },
          {
           "name": "Positive Feedback Count",
           "type": "integer"
          },
          {
           "name": "Division Name",
           "type": "string"
          },
          {
           "name": "Department Name",
           "type": "string"
          },
          {
           "name": "Class Name",
           "type": "string"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 5,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review ID</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review ID  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
       "0          0          767   33  ...       Initmates        Intimate   Intimates\n",
       "1          1         1080   34  ...         General         Dresses     Dresses\n",
       "2          2         1077   60  ...         General         Dresses     Dresses\n",
       "3          3         1049   50  ...  General Petite         Bottoms       Pants\n",
       "4          4          847   47  ...         General            Tops     Blouses\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "reviews = pd.read_csv(\"womens_clothing_e-commerce_reviews.csv\")\n",
    "\n",
    "# Display the first few entries\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ec3a920-be9e-475e-96f5-fe7be47f46e3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1704814766090,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n# Use as many cells as you need."
   },
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Use as many cells as you need.\n",
    "\n",
    "# Create and store the embeddings for reviews in one API call\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "responses = client.embeddings.create(input=review_texts.tolist(), model=EMBEDDING_MODEL).model_dump()\n",
    "embeddings = [response[\"embedding\"] for response in responses[\"data\"]]\n",
    "\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction\n",
    "def apply_tsne(embeddings):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    return tsne.fit_transform(embeddings)\n",
    "\n",
    "embeddings_2d = apply_tsne(np.array(embeddings))\n",
    "\n",
    "# Plotting the results of t-SNE\n",
    "def plot_tsne(tsne_results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, point in enumerate(tsne_results):\n",
    "        plt.scatter(point[0], point[1], alpha=0.5)\n",
    "        plt.text(point[0], point[1], str(i), fontsize=8, verticalalignment='center')\n",
    "    plt.title(\"t-SNE Visualization of Review Embeddings\")\n",
    "    plt.xlabel(\"t-SNE feature 1\")\n",
    "    plt.ylabel(\"t-SNE feature 2\")\n",
    "    plt.show()\n",
    "\n",
    "plot_tsne(embeddings_2d)\n",
    "\n",
    "# Define topics\n",
    "categories = [\"Quality\", \"Fit\", \"Style\", \"Comfort\"]\n",
    "\n",
    "# Create embeddings for all categories in one API call\n",
    "category_responses = client.embeddings.create(input=categories, model=EMBEDDING_MODEL).model_dump()\n",
    "\n",
    "# Extract embeddings from the responses and map them to their respective categories\n",
    "category_embeddings = [embedding[\"embedding\"] for embedding in category_responses[\"data\"]]\n",
    "\n",
    "\n",
    "# Function to categorize feedback\n",
    "def categorize_feedback(text_embedding, category_embeddings):\n",
    "    similarities = [{\"distance\": distance.cosine(text_embedding, cat_emb), \"index\":i}\n",
    "                     for i, cat_emb in enumerate(category_embeddings)]\n",
    "    closest = min(similarities, key=lambda x: x[\"index\"])\n",
    "    return categories[closest[\"index\"]]\n",
    "\n",
    "# Categorize feedback\n",
    "feedback_categories = [categorize_feedback(embedding, category_embeddings) for embedding in embeddings]\n",
    "\n",
    "\n",
    "# Initialize Chromadb instance for vector storage\n",
    "client = chromadb.PersistentClient()\n",
    "\n",
    "# Define vector database\n",
    "review_embeddings_db = client.create_collection(\n",
    "    name=\"review_embeddings\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(api_key=openai_api_key))\n",
    "\n",
    "# Store embeddings inside vector database\n",
    "review_embeddings_db.add(\n",
    "    documents=review_texts.tolist(),\n",
    "    ids=[str(i) for i in range(len(review_texts))]\n",
    ")\n",
    "\n",
    "# Function for similarity search using vector db query function\n",
    "def find_similar_reviews(input_text, vector_db, n=3):\n",
    "    collection = client.get_collection(\n",
    "        name=\"review_embeddings\",\n",
    "        embedding_function=OpenAIEmbeddingFunction(api_key=openai_api_key))\n",
    "    results = collection.query(\n",
    "        query_texts=[input_text],\n",
    "        n_results=n\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Example feedback and finding similar feedback\n",
    "example_review = \"Absolutely wonderful - silky and sexy and comfortable\"\n",
    "most_similar_reviews = find_similar_reviews(example_review, review_embeddings_db, 3)[\"documents\"][0]\n",
    "print(most_similar_reviews)\n",
    "\n",
    "# Clean up\n",
    "client.delete_collection(name=\"review_embeddings\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
